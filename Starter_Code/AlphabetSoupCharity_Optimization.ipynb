{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ol6tiiQgVWh6"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the data\n",
        "url = \"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\"\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "yOgYi7KtVecg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing the data\n",
        "# Drop columns 'EIN' and 'NAME'\n",
        "df = df.drop(columns=['EIN', 'NAME'])"
      ],
      "metadata": {
        "id": "C0cAobEmVgJN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binning for 'APPLICATION_TYPE' column\n",
        "application_type_counts = df['APPLICATION_TYPE'].value_counts()\n",
        "cutoff = 500\n",
        "other_types = list(application_type_counts[application_type_counts < cutoff].index)\n",
        "df['APPLICATION_TYPE'] = df['APPLICATION_TYPE'].apply(lambda x: 'Other' if x in other_types else x)"
      ],
      "metadata": {
        "id": "GDf9Uap4ViCX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binning for 'CLASSIFICATION' column\n",
        "classification_counts = df['CLASSIFICATION'].value_counts()\n",
        "cutoff = 1000\n",
        "other_classifications = list(classification_counts[classification_counts < cutoff].index)\n",
        "df['CLASSIFICATION'] = df['CLASSIFICATION'].apply(lambda x: 'Other' if x in other_classifications else x)"
      ],
      "metadata": {
        "id": "QID-oRBKVlut"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical data to numeric using one-hot encoding\n",
        "df = pd.get_dummies(df)"
      ],
      "metadata": {
        "id": "5KKLsK4sVoZm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into features and target\n",
        "X = df.drop(columns=['IS_SUCCESSFUL'])\n",
        "y = df['IS_SUCCESSFUL']"
      ],
      "metadata": {
        "id": "gmcygSCDVq-V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "Ne3LG8Y8Vs6O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardizing the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "gURuI3cYVu_d"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a method that creates a new Sequential model with hyperparameter options\n",
        "def create_model(hp):\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
        "    activation = hp.Choice('activation',['sigmoid', 'relu','tanh'])\n",
        "\n",
        "    # Allow kerastuner to decide number of neurons in first layer\n",
        "    model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
        "    min_value=1,\n",
        "    max_value=30,\n",
        "    step=5), activation=activation, input_dim=X_train_scaled.shape[1]))\n",
        "\n",
        "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
        "    for i in range(hp.Int('num_layers', 1, 8)):\n",
        "        model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
        "            min_value=1,\n",
        "            max_value=30,\n",
        "            step=5),\n",
        "            activation=activation))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "89w-QhakLDUi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install keras_tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olgDSQljadql",
        "outputId": "f3900599-2d5f-46f4-ea14-7925e3c9ce46"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras_tuner in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the kerastuner library\n",
        "import keras_tuner as kt\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    create_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_epochs=20,\n",
        "    hyperband_iterations=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ofpixGoLRzh",
        "outputId": "25f2b208-3169-4439-faec-f7b6ce3f9f80"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from ./untitled_project/tuner0.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the kerastuner search for best hyperparameters\n",
        "tuner.search(X_train_scaled,y_train,epochs=20,validation_data=(X_test_scaled,y_test))"
      ],
      "metadata": {
        "id": "S1E1uQQ7LWXT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get top 3 model hyperparameters and print the values\n",
        "top_hyper = tuner.get_best_hyperparameters(3)\n",
        "for param in top_hyper:\n",
        "    print(param.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcmOcqtdLeI0",
        "outputId": "ed5b0346-36d7-4ac0-a49f-115b7ba1fa0d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'activation': 'relu', 'first_units': 26, 'num_layers': 2, 'units_0': 21, 'units_1': 6, 'units_2': 21, 'units_3': 21, 'units_4': 21, 'units_5': 6, 'units_6': 6, 'units_7': 21, 'tuner/epochs': 20, 'tuner/initial_epoch': 7, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0019'}\n",
            "{'activation': 'relu', 'first_units': 21, 'num_layers': 1, 'units_0': 6, 'units_1': 6, 'units_2': 21, 'units_3': 1, 'units_4': 16, 'units_5': 1, 'units_6': 21, 'units_7': 1, 'tuner/epochs': 3, 'tuner/initial_epoch': 0, 'tuner/bracket': 2, 'tuner/round': 0}\n",
            "{'activation': 'tanh', 'first_units': 6, 'num_layers': 6, 'units_0': 1, 'units_1': 26, 'units_2': 1, 'units_3': 6, 'units_4': 11, 'units_5': 1, 'units_6': 21, 'units_7': 21, 'tuner/epochs': 20, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the top 3 models against the test dataset\n",
        "top_models = tuner.get_best_models(3)\n",
        "for i, model in enumerate(top_models, start=1):\n",
        "    model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "    print(f\"Model {i}: Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwxWYtWWYJqz",
        "outputId": "0d4c59c5-6b0a-4603-ec78-f2731113d7a4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 1s - loss: 0.5534 - accuracy: 0.7279 - 1s/epoch - 5ms/step\n",
            "Model 1: Loss: 0.5534289479255676, Accuracy: 0.7279300093650818\n",
            "268/268 - 1s - loss: 0.5613 - accuracy: 0.7265 - 1s/epoch - 4ms/step\n",
            "Model 2: Loss: 0.5612772107124329, Accuracy: 0.7265306115150452\n",
            "268/268 - 1s - loss: 0.5798 - accuracy: 0.7264 - 959ms/epoch - 4ms/step\n",
            "Model 3: Loss: 0.579780101776123, Accuracy: 0.7264139652252197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model\n",
        "model.save(\"AlphabetSoupCharity_Optimization.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_rGRBpiV8AR",
        "outputId": "68edb357-3c21-4252-b8fc-3a1813ec725b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}