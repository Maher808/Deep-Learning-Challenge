{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ol6tiiQgVWh6"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the data\n",
        "url = \"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\"\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "yOgYi7KtVecg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing the data\n",
        "# Drop columns 'EIN' and 'NAME'\n",
        "df = df.drop(columns=['EIN', 'NAME'])"
      ],
      "metadata": {
        "id": "C0cAobEmVgJN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binning for 'APPLICATION_TYPE' column\n",
        "application_type_counts = df['APPLICATION_TYPE'].value_counts()\n",
        "cutoff = 500\n",
        "other_types = list(application_type_counts[application_type_counts < cutoff].index)\n",
        "df['APPLICATION_TYPE'] = df['APPLICATION_TYPE'].apply(lambda x: 'Other' if x in other_types else x)"
      ],
      "metadata": {
        "id": "GDf9Uap4ViCX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binning for 'CLASSIFICATION' column\n",
        "classification_counts = df['CLASSIFICATION'].value_counts()\n",
        "cutoff = 1000\n",
        "other_classifications = list(classification_counts[classification_counts < cutoff].index)\n",
        "df['CLASSIFICATION'] = df['CLASSIFICATION'].apply(lambda x: 'Other' if x in other_classifications else x)"
      ],
      "metadata": {
        "id": "QID-oRBKVlut"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical data to numeric using one-hot encoding\n",
        "df = pd.get_dummies(df)"
      ],
      "metadata": {
        "id": "5KKLsK4sVoZm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into features and target\n",
        "X = df.drop(columns=['IS_SUCCESSFUL'])\n",
        "y = df['IS_SUCCESSFUL']"
      ],
      "metadata": {
        "id": "gmcygSCDVq-V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "Ne3LG8Y8Vs6O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardizing the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "gURuI3cYVu_d"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the neural network model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(units=80, input_dim=len(X_train_scaled[0]), activation='relu'),\n",
        "    tf.keras.layers.Dense(units=30, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "Hse1OzScVxe-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ikAPlVG6VzVl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "model.fit(X_train_scaled, y_train, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aadz4KeKV1KN",
        "outputId": "a7e73ae2-4fa7-450a-aa95-84d271a708db"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "804/804 - 3s - loss: 0.5727 - accuracy: 0.7203 - 3s/epoch - 4ms/step\n",
            "Epoch 2/100\n",
            "804/804 - 1s - loss: 0.5542 - accuracy: 0.7309 - 1s/epoch - 1ms/step\n",
            "Epoch 3/100\n",
            "804/804 - 1s - loss: 0.5520 - accuracy: 0.7322 - 1s/epoch - 1ms/step\n",
            "Epoch 4/100\n",
            "804/804 - 1s - loss: 0.5512 - accuracy: 0.7311 - 1s/epoch - 1ms/step\n",
            "Epoch 5/100\n",
            "804/804 - 1s - loss: 0.5495 - accuracy: 0.7339 - 1s/epoch - 1ms/step\n",
            "Epoch 6/100\n",
            "804/804 - 1s - loss: 0.5486 - accuracy: 0.7328 - 1s/epoch - 2ms/step\n",
            "Epoch 7/100\n",
            "804/804 - 2s - loss: 0.5483 - accuracy: 0.7333 - 2s/epoch - 2ms/step\n",
            "Epoch 8/100\n",
            "804/804 - 1s - loss: 0.5466 - accuracy: 0.7347 - 1s/epoch - 1ms/step\n",
            "Epoch 9/100\n",
            "804/804 - 2s - loss: 0.5462 - accuracy: 0.7350 - 2s/epoch - 2ms/step\n",
            "Epoch 10/100\n",
            "804/804 - 2s - loss: 0.5456 - accuracy: 0.7359 - 2s/epoch - 3ms/step\n",
            "Epoch 11/100\n",
            "804/804 - 1s - loss: 0.5450 - accuracy: 0.7349 - 1s/epoch - 1ms/step\n",
            "Epoch 12/100\n",
            "804/804 - 1s - loss: 0.5445 - accuracy: 0.7364 - 1s/epoch - 2ms/step\n",
            "Epoch 13/100\n",
            "804/804 - 2s - loss: 0.5444 - accuracy: 0.7350 - 2s/epoch - 2ms/step\n",
            "Epoch 14/100\n",
            "804/804 - 3s - loss: 0.5440 - accuracy: 0.7364 - 3s/epoch - 4ms/step\n",
            "Epoch 15/100\n",
            "804/804 - 1s - loss: 0.5431 - accuracy: 0.7363 - 1s/epoch - 1ms/step\n",
            "Epoch 16/100\n",
            "804/804 - 1s - loss: 0.5436 - accuracy: 0.7366 - 1s/epoch - 1ms/step\n",
            "Epoch 17/100\n",
            "804/804 - 1s - loss: 0.5427 - accuracy: 0.7361 - 1s/epoch - 1ms/step\n",
            "Epoch 18/100\n",
            "804/804 - 1s - loss: 0.5422 - accuracy: 0.7382 - 1s/epoch - 1ms/step\n",
            "Epoch 19/100\n",
            "804/804 - 1s - loss: 0.5423 - accuracy: 0.7379 - 1s/epoch - 2ms/step\n",
            "Epoch 20/100\n",
            "804/804 - 2s - loss: 0.5419 - accuracy: 0.7388 - 2s/epoch - 3ms/step\n",
            "Epoch 21/100\n",
            "804/804 - 2s - loss: 0.5419 - accuracy: 0.7389 - 2s/epoch - 3ms/step\n",
            "Epoch 22/100\n",
            "804/804 - 2s - loss: 0.5417 - accuracy: 0.7381 - 2s/epoch - 2ms/step\n",
            "Epoch 23/100\n",
            "804/804 - 1s - loss: 0.5408 - accuracy: 0.7391 - 1s/epoch - 1ms/step\n",
            "Epoch 24/100\n",
            "804/804 - 1s - loss: 0.5417 - accuracy: 0.7383 - 1s/epoch - 1ms/step\n",
            "Epoch 25/100\n",
            "804/804 - 1s - loss: 0.5407 - accuracy: 0.7382 - 1s/epoch - 1ms/step\n",
            "Epoch 26/100\n",
            "804/804 - 1s - loss: 0.5408 - accuracy: 0.7378 - 1s/epoch - 1ms/step\n",
            "Epoch 27/100\n",
            "804/804 - 1s - loss: 0.5410 - accuracy: 0.7378 - 1s/epoch - 1ms/step\n",
            "Epoch 28/100\n",
            "804/804 - 1s - loss: 0.5404 - accuracy: 0.7387 - 1s/epoch - 1ms/step\n",
            "Epoch 29/100\n",
            "804/804 - 1s - loss: 0.5400 - accuracy: 0.7389 - 1s/epoch - 1ms/step\n",
            "Epoch 30/100\n",
            "804/804 - 1s - loss: 0.5405 - accuracy: 0.7395 - 1s/epoch - 1ms/step\n",
            "Epoch 31/100\n",
            "804/804 - 1s - loss: 0.5397 - accuracy: 0.7397 - 1s/epoch - 1ms/step\n",
            "Epoch 32/100\n",
            "804/804 - 2s - loss: 0.5397 - accuracy: 0.7389 - 2s/epoch - 2ms/step\n",
            "Epoch 33/100\n",
            "804/804 - 1s - loss: 0.5396 - accuracy: 0.7397 - 1s/epoch - 2ms/step\n",
            "Epoch 34/100\n",
            "804/804 - 1s - loss: 0.5393 - accuracy: 0.7391 - 1s/epoch - 2ms/step\n",
            "Epoch 35/100\n",
            "804/804 - 1s - loss: 0.5394 - accuracy: 0.7402 - 1s/epoch - 2ms/step\n",
            "Epoch 36/100\n",
            "804/804 - 1s - loss: 0.5392 - accuracy: 0.7393 - 1s/epoch - 1ms/step\n",
            "Epoch 37/100\n",
            "804/804 - 1s - loss: 0.5390 - accuracy: 0.7394 - 1s/epoch - 1ms/step\n",
            "Epoch 38/100\n",
            "804/804 - 1s - loss: 0.5390 - accuracy: 0.7395 - 1s/epoch - 1ms/step\n",
            "Epoch 39/100\n",
            "804/804 - 1s - loss: 0.5392 - accuracy: 0.7392 - 1s/epoch - 1ms/step\n",
            "Epoch 40/100\n",
            "804/804 - 1s - loss: 0.5383 - accuracy: 0.7404 - 1s/epoch - 1ms/step\n",
            "Epoch 41/100\n",
            "804/804 - 1s - loss: 0.5385 - accuracy: 0.7399 - 1s/epoch - 2ms/step\n",
            "Epoch 42/100\n",
            "804/804 - 2s - loss: 0.5384 - accuracy: 0.7395 - 2s/epoch - 2ms/step\n",
            "Epoch 43/100\n",
            "804/804 - 1s - loss: 0.5382 - accuracy: 0.7395 - 1s/epoch - 2ms/step\n",
            "Epoch 44/100\n",
            "804/804 - 1s - loss: 0.5384 - accuracy: 0.7396 - 1s/epoch - 1ms/step\n",
            "Epoch 45/100\n",
            "804/804 - 1s - loss: 0.5383 - accuracy: 0.7394 - 1s/epoch - 1ms/step\n",
            "Epoch 46/100\n",
            "804/804 - 1s - loss: 0.5378 - accuracy: 0.7411 - 1s/epoch - 1ms/step\n",
            "Epoch 47/100\n",
            "804/804 - 1s - loss: 0.5379 - accuracy: 0.7392 - 1s/epoch - 1ms/step\n",
            "Epoch 48/100\n",
            "804/804 - 1s - loss: 0.5381 - accuracy: 0.7399 - 1s/epoch - 1ms/step\n",
            "Epoch 49/100\n",
            "804/804 - 1s - loss: 0.5374 - accuracy: 0.7409 - 1s/epoch - 1ms/step\n",
            "Epoch 50/100\n",
            "804/804 - 1s - loss: 0.5372 - accuracy: 0.7393 - 1s/epoch - 1ms/step\n",
            "Epoch 51/100\n",
            "804/804 - 1s - loss: 0.5373 - accuracy: 0.7404 - 1s/epoch - 2ms/step\n",
            "Epoch 52/100\n",
            "804/804 - 2s - loss: 0.5373 - accuracy: 0.7408 - 2s/epoch - 2ms/step\n",
            "Epoch 53/100\n",
            "804/804 - 1s - loss: 0.5369 - accuracy: 0.7407 - 1s/epoch - 2ms/step\n",
            "Epoch 54/100\n",
            "804/804 - 1s - loss: 0.5368 - accuracy: 0.7409 - 1s/epoch - 1ms/step\n",
            "Epoch 55/100\n",
            "804/804 - 1s - loss: 0.5367 - accuracy: 0.7404 - 1s/epoch - 1ms/step\n",
            "Epoch 56/100\n",
            "804/804 - 1s - loss: 0.5372 - accuracy: 0.7404 - 1s/epoch - 1ms/step\n",
            "Epoch 57/100\n",
            "804/804 - 1s - loss: 0.5368 - accuracy: 0.7407 - 1s/epoch - 2ms/step\n",
            "Epoch 58/100\n",
            "804/804 - 1s - loss: 0.5368 - accuracy: 0.7409 - 1s/epoch - 1ms/step\n",
            "Epoch 59/100\n",
            "804/804 - 1s - loss: 0.5368 - accuracy: 0.7414 - 1s/epoch - 1ms/step\n",
            "Epoch 60/100\n",
            "804/804 - 1s - loss: 0.5365 - accuracy: 0.7411 - 1s/epoch - 1ms/step\n",
            "Epoch 61/100\n",
            "804/804 - 1s - loss: 0.5363 - accuracy: 0.7409 - 1s/epoch - 2ms/step\n",
            "Epoch 62/100\n",
            "804/804 - 2s - loss: 0.5366 - accuracy: 0.7404 - 2s/epoch - 2ms/step\n",
            "Epoch 63/100\n",
            "804/804 - 1s - loss: 0.5362 - accuracy: 0.7411 - 1s/epoch - 2ms/step\n",
            "Epoch 64/100\n",
            "804/804 - 1s - loss: 0.5362 - accuracy: 0.7407 - 1s/epoch - 1ms/step\n",
            "Epoch 65/100\n",
            "804/804 - 1s - loss: 0.5359 - accuracy: 0.7413 - 1s/epoch - 1ms/step\n",
            "Epoch 66/100\n",
            "804/804 - 1s - loss: 0.5360 - accuracy: 0.7406 - 1s/epoch - 1ms/step\n",
            "Epoch 67/100\n",
            "804/804 - 1s - loss: 0.5362 - accuracy: 0.7414 - 1s/epoch - 1ms/step\n",
            "Epoch 68/100\n",
            "804/804 - 1s - loss: 0.5360 - accuracy: 0.7406 - 1s/epoch - 1ms/step\n",
            "Epoch 69/100\n",
            "804/804 - 1s - loss: 0.5355 - accuracy: 0.7414 - 1s/epoch - 1ms/step\n",
            "Epoch 70/100\n",
            "804/804 - 1s - loss: 0.5362 - accuracy: 0.7415 - 1s/epoch - 1ms/step\n",
            "Epoch 71/100\n",
            "804/804 - 1s - loss: 0.5357 - accuracy: 0.7407 - 1s/epoch - 1ms/step\n",
            "Epoch 72/100\n",
            "804/804 - 2s - loss: 0.5353 - accuracy: 0.7411 - 2s/epoch - 2ms/step\n",
            "Epoch 73/100\n",
            "804/804 - 1s - loss: 0.5358 - accuracy: 0.7403 - 1s/epoch - 2ms/step\n",
            "Epoch 74/100\n",
            "804/804 - 1s - loss: 0.5354 - accuracy: 0.7409 - 1s/epoch - 1ms/step\n",
            "Epoch 75/100\n",
            "804/804 - 1s - loss: 0.5350 - accuracy: 0.7411 - 1s/epoch - 1ms/step\n",
            "Epoch 76/100\n",
            "804/804 - 1s - loss: 0.5352 - accuracy: 0.7414 - 1s/epoch - 1ms/step\n",
            "Epoch 77/100\n",
            "804/804 - 1s - loss: 0.5356 - accuracy: 0.7409 - 1s/epoch - 1ms/step\n",
            "Epoch 78/100\n",
            "804/804 - 1s - loss: 0.5357 - accuracy: 0.7411 - 1s/epoch - 1ms/step\n",
            "Epoch 79/100\n",
            "804/804 - 1s - loss: 0.5351 - accuracy: 0.7404 - 1s/epoch - 1ms/step\n",
            "Epoch 80/100\n",
            "804/804 - 1s - loss: 0.5349 - accuracy: 0.7414 - 1s/epoch - 1ms/step\n",
            "Epoch 81/100\n",
            "804/804 - 1s - loss: 0.5349 - accuracy: 0.7415 - 1s/epoch - 1ms/step\n",
            "Epoch 82/100\n",
            "804/804 - 2s - loss: 0.5345 - accuracy: 0.7409 - 2s/epoch - 2ms/step\n",
            "Epoch 83/100\n",
            "804/804 - 1s - loss: 0.5353 - accuracy: 0.7414 - 1s/epoch - 2ms/step\n",
            "Epoch 84/100\n",
            "804/804 - 1s - loss: 0.5350 - accuracy: 0.7406 - 1s/epoch - 1ms/step\n",
            "Epoch 85/100\n",
            "804/804 - 1s - loss: 0.5347 - accuracy: 0.7412 - 1s/epoch - 1ms/step\n",
            "Epoch 86/100\n",
            "804/804 - 1s - loss: 0.5346 - accuracy: 0.7408 - 1s/epoch - 1ms/step\n",
            "Epoch 87/100\n",
            "804/804 - 1s - loss: 0.5348 - accuracy: 0.7414 - 1s/epoch - 1ms/step\n",
            "Epoch 88/100\n",
            "804/804 - 1s - loss: 0.5349 - accuracy: 0.7413 - 1s/epoch - 1ms/step\n",
            "Epoch 89/100\n",
            "804/804 - 1s - loss: 0.5345 - accuracy: 0.7418 - 1s/epoch - 1ms/step\n",
            "Epoch 90/100\n",
            "804/804 - 1s - loss: 0.5345 - accuracy: 0.7414 - 1s/epoch - 2ms/step\n",
            "Epoch 91/100\n",
            "804/804 - 1s - loss: 0.5346 - accuracy: 0.7421 - 1s/epoch - 1ms/step\n",
            "Epoch 92/100\n",
            "804/804 - 2s - loss: 0.5348 - accuracy: 0.7412 - 2s/epoch - 2ms/step\n",
            "Epoch 93/100\n",
            "804/804 - 2s - loss: 0.5346 - accuracy: 0.7410 - 2s/epoch - 2ms/step\n",
            "Epoch 94/100\n",
            "804/804 - 1s - loss: 0.5349 - accuracy: 0.7410 - 1s/epoch - 2ms/step\n",
            "Epoch 95/100\n",
            "804/804 - 1s - loss: 0.5352 - accuracy: 0.7416 - 1s/epoch - 1ms/step\n",
            "Epoch 96/100\n",
            "804/804 - 1s - loss: 0.5346 - accuracy: 0.7417 - 1s/epoch - 1ms/step\n",
            "Epoch 97/100\n",
            "804/804 - 1s - loss: 0.5344 - accuracy: 0.7418 - 1s/epoch - 1ms/step\n",
            "Epoch 98/100\n",
            "804/804 - 1s - loss: 0.5341 - accuracy: 0.7411 - 1s/epoch - 1ms/step\n",
            "Epoch 99/100\n",
            "804/804 - 1s - loss: 0.5340 - accuracy: 0.7414 - 1s/epoch - 1ms/step\n",
            "Epoch 100/100\n",
            "804/804 - 1s - loss: 0.5341 - accuracy: 0.7414 - 1s/epoch - 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f1937bdf4f0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model\n",
        "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV6Gh2sxV3ak",
        "outputId": "d1c2cc69-c7e1-492b-9d81-9c32efe159f2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - loss: 0.5589 - accuracy: 0.7258 - 498ms/epoch - 2ms/step\n",
            "Loss: 0.5588554739952087, Accuracy: 0.7258309125900269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model\n",
        "model.save(\"AlphabetSoupCharity_Optimization.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_rGRBpiV8AR",
        "outputId": "67e0edef-56f0-45fc-bc02-d19569d4b5c0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}